name: NewHomeSource Scraper

on:
  schedule:
    # Run twice daily at 6 AM and 6 PM PST (2 AM and 2 PM UTC)
    - cron: '0 2,14 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run scraper
      id: scraper
      env:
        MONGO_DB_USERNAME: ${{ secrets.MONGO_DB_USERNAME }}
        MONGO_DB_PASSWORD: ${{ secrets.MONGO_DB_PASSWORD }}

      run: |
        python newhomesource.py
        echo "SCRAPER_EXIT_CODE=$?" >> $GITHUB_OUTPUT
        
    - name: Check scraper results
      run: |
        echo "=== SCRAPER RUN SUMMARY ==="
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          echo "üìã Log file: $LOG_FILE"
          echo ""
          echo "=== LAST 20 LINES OF LOG ==="
          tail -n 20 "$LOG_FILE"
          echo ""
          
          # Check for success/failure indicators
          if grep -q "üéâ OVERALL STATUS: SUCCESS" "$LOG_FILE"; then
            echo "‚úÖ SCRAPER STATUS: SUCCESS"
            echo "scraper_status=success" >> $GITHUB_OUTPUT
          elif grep -q "üí• OVERALL STATUS: FAILED" "$LOG_FILE"; then
            echo "‚ùå SCRAPER STATUS: FAILED"
            echo "scraper_status=failed" >> $GITHUB_OUTPUT
            
            # Show errors if any
            echo ""
            echo "=== ERRORS FOUND ==="
            grep "‚ùå" "$LOG_FILE" || echo "No specific errors found in log"
          else
            echo "‚ö†Ô∏è SCRAPER STATUS: UNKNOWN"
            echo "scraper_status=unknown" >> $GITHUB_OUTPUT
          fi
          
          # Extract statistics
          echo ""
          echo "=== STATISTICS ==="
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç)" "$LOG_FILE" | tail -n 5
          
        else
          echo "‚ùå No log file found - scraper may have failed to start"
          echo "scraper_status=no_log" >> $GITHUB_OUTPUT
        fi
        
    - name: Upload logs and data
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs-${{ github.run_number }}
        path: |
          logging/nhs/scraper_log_*.log
          logging/nhs/newhomesource_data.json
        retention-days: 7
        
    - name: Report status in job summary
      if: always()
      run: |
        echo "# üè† NewHomeSource Scraper Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Time:** $(date) (Scheduled for 6 AM & 6 PM PST)" >> $GITHUB_STEP_SUMMARY
        echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Find the latest log file
        LOG_FILE=$(ls -t scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          if grep -q "üéâ OVERALL STATUS: SUCCESS" "$LOG_FILE"; then
            echo "## ‚úÖ Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
          elif grep -q "üí• OVERALL STATUS: FAILED" "$LOG_FILE"; then
            echo "## ‚ùå Status: FAILED" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ‚ö†Ô∏è Status: UNKNOWN" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Summary Statistics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç)" "$LOG_FILE" | tail -n 5 >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Show any errors
          if grep -q "‚ùå" "$LOG_FILE"; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ö†Ô∏è Errors Encountered" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            grep "‚ùå" "$LOG_FILE" | head -n 10 >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
          
        else
          echo "## ‚ùå Status: NO LOG FILE" >> $GITHUB_STEP_SUMMARY
          echo "Scraper failed to generate log file." >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Fail job if scraper failed
      if: failure() || steps.scraper.outputs.SCRAPER_EXIT_CODE != '0'
      run: |
        echo "‚ùå Scraper failed with exit code: ${{ steps.scraper.outputs.SCRAPER_EXIT_CODE }}"
        exit 1
