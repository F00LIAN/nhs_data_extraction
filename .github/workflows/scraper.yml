name: NewHomeSource Scraper

on:
  schedule:
    # Run once daily at 6 AM PST (2 AM UTC)
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run scraper with browser fallback
      id: scraper
      env:
        MONGO_DB_USERNAME: ${{ secrets.MONGO_DB_USERNAME }}
        MONGO_DB_PASSWORD: ${{ secrets.MONGO_DB_PASSWORD }}
      run: |
        # List of browsers to try in order
        BROWSERS=("chrome" "firefox" "safari" "chrome_android" "safari_ios")
        SUCCESS=false
        SUCCESSFUL_BROWSER=""
        FINAL_EXIT_CODE=1
        
        echo "üîÑ Starting scraper with browser fallback protocol"
        echo "üìã Browser order: ${BROWSERS[*]}"
        echo ""
        
        for browser in "${BROWSERS[@]}"; do
          echo "üåê Attempting scrape with browser: $browser"
          echo "========================================"
          
          if python newhomesource.py --browser "$browser"; then
            echo "‚úÖ SUCCESS with browser: $browser"
            SUCCESS=true
            SUCCESSFUL_BROWSER="$browser"
            FINAL_EXIT_CODE=0
            break
          else
            echo "‚ùå FAILED with browser: $browser (exit code: $?)"
            echo ""
            
            # Show last few lines of the latest log for debugging
            LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
            if [ -n "$LOG_FILE" ]; then
              echo "üìã Last 5 lines from $LOG_FILE:"
              tail -n 5 "$LOG_FILE"
              echo ""
            fi
          fi
        done
        
        echo "========================================"
        if [ "$SUCCESS" = true ]; then
          echo "üéâ SCRAPER COMPLETED SUCCESSFULLY with browser: $SUCCESSFUL_BROWSER"
          echo "successful_browser=$SUCCESSFUL_BROWSER" >> $GITHUB_OUTPUT
        else
          echo "üí• SCRAPER FAILED with all browsers: ${BROWSERS[*]}"
          echo "successful_browser=none" >> $GITHUB_OUTPUT
        fi
        
        echo "SCRAPER_EXIT_CODE=$FINAL_EXIT_CODE" >> $GITHUB_OUTPUT
        exit $FINAL_EXIT_CODE
        
    - name: Check scraper results
      run: |
        echo "=== SCRAPER RUN SUMMARY ==="
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          echo "üìã Log file: $LOG_FILE"
          echo ""
          echo "=== LAST 20 LINES OF LOG ==="
          tail -n 20 "$LOG_FILE"
          echo ""
          
          # Check for success/failure indicators
          if grep -q "üéâ OVERALL STATUS: SUCCESS" "$LOG_FILE"; then
            echo "‚úÖ SCRAPER STATUS: SUCCESS"
            echo "scraper_status=success" >> $GITHUB_OUTPUT
          elif grep -q "üí• OVERALL STATUS: FAILED" "$LOG_FILE"; then
            echo "‚ùå SCRAPER STATUS: FAILED"
            echo "scraper_status=failed" >> $GITHUB_OUTPUT
            
            # Show errors if any
            echo ""
            echo "=== ERRORS FOUND ==="
            grep "‚ùå" "$LOG_FILE" || echo "No specific errors found in log"
          else
            echo "‚ö†Ô∏è SCRAPER STATUS: UNKNOWN"
            echo "scraper_status=unknown" >> $GITHUB_OUTPUT
          fi
          
          # Extract statistics
          echo ""
          echo "=== STATISTICS ==="
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç)" "$LOG_FILE" | tail -n 5
          
        else
          echo "‚ùå No log file found - scraper may have failed to start"
          echo "scraper_status=no_log" >> $GITHUB_OUTPUT
        fi
        
    - name: Upload logs and data
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs-${{ github.run_number }}
        path: |
          logging/nhs/scraper_log_*.log
          logging/nhs/newhomesource_data.json
        retention-days: 7
        
    - name: Report status in job summary
      if: always()
      run: |
        echo "# üè† NewHomeSource Scraper Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Time:** $(date) (Scheduled for 6 AM PST)" >> $GITHUB_STEP_SUMMARY
        echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "**Successful Browser:** ${{ steps.scraper.outputs.successful_browser }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          if grep -q "üéâ OVERALL STATUS: SUCCESS" "$LOG_FILE"; then
            echo "## ‚úÖ Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
          elif grep -q "üí• OVERALL STATUS: FAILED" "$LOG_FILE"; then
            echo "## ‚ùå Status: FAILED" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ‚ö†Ô∏è Status: UNKNOWN" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Summary Statistics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç)" "$LOG_FILE" | tail -n 5 >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Show any errors
          if grep -q "‚ùå" "$LOG_FILE"; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ö†Ô∏è Errors Encountered" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            grep "‚ùå" "$LOG_FILE" | head -n 10 >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
          
        else
          echo "## ‚ùå Status: NO LOG FILE" >> $GITHUB_STEP_SUMMARY
          echo "Scraper failed to generate log file." >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Fail job if scraper failed
      if: failure() || steps.scraper.outputs.SCRAPER_EXIT_CODE != '0'
      run: |
        echo "‚ùå Scraper failed with exit code: ${{ steps.scraper.outputs.SCRAPER_EXIT_CODE }}"
        echo "‚ùå All browsers failed: chrome, firefox, safari, chrome_android, safari_ios"
        exit 1
