name: NewHomeSource Scraper

on:
  schedule:
    # Run once daily at 6 AM PST (2 AM UTC)
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        cd src/scraper
        pip install -r requirements.txt
        
    - name: Run NewHomeSource scraper (Stage 1 + Stage 2)
      id: scraper
      env:
        MONGO_DB_USERNAME: ${{ secrets.MONGO_DB_USERNAME }}
        MONGO_DB_PASSWORD: ${{ secrets.MONGO_DB_PASSWORD }}
        MONGO_DB_URI: mongodb+srv://${{ secrets.MONGO_DB_USERNAME }}:${{ secrets.MONGO_DB_PASSWORD }}@cluster0.lz6kt.mongodb.net/newhomesource?retryWrites=true&w=majority&appName=Cluster0
      run: |
        cd src/scraper
        
        # List of browsers to try in order
        BROWSERS=("chrome" "firefox" "safari" "chrome_android" "safari_ios")
        SUCCESS=false
        SUCCESSFUL_BROWSER=""
        FINAL_EXIT_CODE=1
        
        echo "üîÑ Starting NewHomeSource full extraction with browser fallback"
        echo "üìã Browser order: ${BROWSERS[*]}"
        echo "üéØ Running Stage 1 (listings) + Stage 2 (community data) + Price tracking"
        echo ""
        
        for browser in "${BROWSERS[@]}"; do
          echo "üåê Attempting full extraction with browser: $browser"
          echo "========================================"
          
          if python run_nhs.py --stage full --max-concurrent 8 --browser "$browser"; then
            echo "‚úÖ SUCCESS with browser: $browser"
            SUCCESS=true
            SUCCESSFUL_BROWSER="$browser"
            FINAL_EXIT_CODE=0
            break
          else
            EXIT_CODE=$?
            echo "‚ùå FAILED with browser: $browser (exit code: $EXIT_CODE)"
            echo ""
            
            # Show last few lines of the latest log for debugging
            LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
            if [ -n "$LOG_FILE" ]; then
              echo "üìã Last 10 lines from $LOG_FILE:"
              tail -n 10 "$LOG_FILE"
              echo ""
            fi
            
            # Wait a bit before trying next browser
            echo "‚è≥ Waiting 30 seconds before trying next browser..."
            sleep 30
          fi
        done
        
        echo "========================================"
        if [ "$SUCCESS" = true ]; then
          echo "üéâ NEWHOMESOURCE EXTRACTION COMPLETED SUCCESSFULLY with browser: $SUCCESSFUL_BROWSER"
          echo "‚úÖ Stage 1 (listings) and Stage 2 (community data) both completed"
          echo "üí∞ Price tracking data captured and stored"
          echo "successful_browser=$SUCCESSFUL_BROWSER" >> $GITHUB_OUTPUT
        else
          echo "üí• EXTRACTION FAILED with all browsers: ${BROWSERS[*]}"
          echo "‚ùå Both Stage 1 and Stage 2 were attempted but failed"
          echo "successful_browser=none" >> $GITHUB_OUTPUT
        fi
        
        echo "SCRAPER_EXIT_CODE=$FINAL_EXIT_CODE" >> $GITHUB_OUTPUT
        exit $FINAL_EXIT_CODE
        
    - name: Check scraper results
      run: |
        cd src/scraper
        echo "=== NEWHOMESOURCE EXTRACTION SUMMARY ==="
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          echo "üìã Log file: $LOG_FILE"
          echo ""
          echo "=== LAST 25 LINES OF LOG ==="
          tail -n 25 "$LOG_FILE"
          echo ""
          
          # Check for success/failure indicators from both stages
          STAGE1_SUCCESS=$(grep -c "üèÅ Stage 1 Extraction Complete!" "$LOG_FILE" || echo "0")
          STAGE2_SUCCESS=$(grep -c "üèÅ Stage 2 Extraction Complete!" "$LOG_FILE" || echo "0")
          OVERALL_SUCCESS=$(grep -c "üéä FULL EXTRACTION SUMMARY" "$LOG_FILE" || echo "0")
          
          if [ "$OVERALL_SUCCESS" -gt 0 ] && [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -gt 0 ]; then
            echo "‚úÖ EXTRACTION STATUS: FULL SUCCESS"
            echo "‚úÖ Stage 1 (Listings): COMPLETED"
            echo "‚úÖ Stage 2 (Community Data): COMPLETED"
            echo "scraper_status=success" >> $GITHUB_OUTPUT
          elif [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -eq 0 ]; then
            echo "‚ö†Ô∏è EXTRACTION STATUS: PARTIAL SUCCESS"
            echo "‚úÖ Stage 1 (Listings): COMPLETED"
            echo "‚ùå Stage 2 (Community Data): FAILED"
            echo "scraper_status=partial" >> $GITHUB_OUTPUT
          elif [ "$STAGE1_SUCCESS" -eq 0 ]; then
            echo "‚ùå EXTRACTION STATUS: FAILED"
            echo "‚ùå Stage 1 (Listings): FAILED"
            echo "‚ùå Stage 2 (Community Data): NOT ATTEMPTED"
            echo "scraper_status=failed" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è EXTRACTION STATUS: UNKNOWN"
            echo "scraper_status=unknown" >> $GITHUB_OUTPUT
          fi
          
          # Show errors if any
          echo ""
          echo "=== ERRORS FOUND ==="
          grep "‚ùå" "$LOG_FILE" | head -n 10 || echo "No specific errors found in log"
          
          # Extract statistics from both stages
          echo ""
          echo "=== STAGE STATISTICS ==="
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç|üÜï|üîÑ|‚úÖ)" "$LOG_FILE" | grep -E "(processed|new|updated|success|error)" | tail -n 10
          
        else
          echo "‚ùå No log file found - scraper may have failed to start"
          echo "scraper_status=no_log" >> $GITHUB_OUTPUT
        fi
        
    - name: Upload logs and data
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs-${{ github.run_number }}
        path: |
          src/scraper/logging/nhs/scraper_log_*.log
        retention-days: 7
        
    - name: Report status in job summary
      if: always()
      run: |
        cd src/scraper
        echo "# üè† NewHomeSource Full Extraction Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Time:** $(date) (Scheduled for 6 AM PST)" >> $GITHUB_STEP_SUMMARY
        echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "**Successful Browser:** ${{ steps.scraper.outputs.successful_browser }}" >> $GITHUB_STEP_SUMMARY
        echo "**Extraction Type:** Stage 1 (Listings) + Stage 2 (Community Data) + Price Tracking" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          # Check for success/failure indicators from both stages
          STAGE1_SUCCESS=$(grep -c "üèÅ Stage 1 Extraction Complete!" "$LOG_FILE" || echo "0")
          STAGE2_SUCCESS=$(grep -c "üèÅ Stage 2 Extraction Complete!" "$LOG_FILE" || echo "0")
          OVERALL_SUCCESS=$(grep -c "üéä FULL EXTRACTION SUMMARY" "$LOG_FILE" || echo "0")
          
          if [ "$OVERALL_SUCCESS" -gt 0 ] && [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -gt 0 ]; then
            echo "## ‚úÖ Status: FULL SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ Stage 1 (Listings): COMPLETED" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ Stage 2 (Community Data): COMPLETED" >> $GITHUB_STEP_SUMMARY
            echo "- üí∞ Price Tracking: ACTIVE" >> $GITHUB_STEP_SUMMARY
          elif [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -eq 0 ]; then
            echo "## ‚ö†Ô∏è Status: PARTIAL SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ Stage 1 (Listings): COMPLETED" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ùå Stage 2 (Community Data): FAILED" >> $GITHUB_STEP_SUMMARY
          elif [ "$STAGE1_SUCCESS" -eq 0 ]; then
            echo "## ‚ùå Status: FAILED" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ùå Stage 1 (Listings): FAILED" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ùå Stage 2 (Community Data): NOT ATTEMPTED" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ‚ö†Ô∏è Status: UNKNOWN" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Extraction Statistics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç|üÜï|üîÑ)" "$LOG_FILE" | grep -E "(processed|new|updated|success|error|complete)" | tail -n 8 >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Show any errors
          if grep -q "‚ùå" "$LOG_FILE"; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ö†Ô∏è Errors Encountered" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            grep "‚ùå" "$LOG_FILE" | head -n 10 >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
          
        else
          echo "## ‚ùå Status: NO LOG FILE" >> $GITHUB_STEP_SUMMARY
          echo "Scraper failed to generate log file." >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Fail job if scraper failed
      if: failure() || steps.scraper.outputs.SCRAPER_EXIT_CODE != '0'
      run: |
        echo "‚ùå NewHomeSource extraction failed with exit code: ${{ steps.scraper.outputs.SCRAPER_EXIT_CODE }}"
        echo "‚ùå All browsers failed: chrome, firefox, safari, chrome_android, safari_ios"
        echo "‚ùå Check Stage 1 (listings) and Stage 2 (community data) logs for details"
        exit 1
