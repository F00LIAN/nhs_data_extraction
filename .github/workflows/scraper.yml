name: NewHomeSource Modular Scraper

on:
  schedule:
    # Run once daily at 6 AM PST (2 AM UTC)
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger
    inputs:
      stage:
        description: 'Which stage to run'
        required: false
        default: 'full'
        type: choice
        options:
        - 'full'
        - '1'
        - '2'
      max_concurrent:
        description: 'Maximum concurrent requests'
        required: false
        default: '8'
        type: string
      browser:
        description: 'Browser to use (if not using fallback)'
        required: false
        default: 'auto'
        type: choice
        options:
        - 'auto'
        - 'chrome'
        - 'firefox'
        - 'safari'
        - 'chrome_android'
        - 'safari_ios'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      working-directory: .
        
    - name: Validate modular structure
      run: |
        echo "üîç Validating modular scraper structure..."
        
        # Check main entry point
        if [ ! -f "run_nhs.py" ]; then
          echo "‚ùå Missing main entry point: run_nhs.py"
          exit 1
        fi
        
        # Check modular directories
        for dir in "stageone" "stagetwo" "shared"; do
          if [ ! -d "$dir" ]; then
            echo "‚ùå Missing modular directory: $dir"
            exit 1
          fi
          echo "‚úÖ Found directory: $dir"
        done
        
        # Check key modular files
        declare -A files=(
          ["stageone/scraping_orchestrator.py"]="Stage 1 orchestrator"
          ["stageone/url_generator.py"]="URL generator"
          ["stagetwo/orchestrator.py"]="Stage 2 orchestrator"
          ["stagetwo/data_fetcher.py"]="Data fetcher"
          ["shared/price_tracker.py"]="Price tracker"
        )
        
        for file in "${!files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "‚ùå Missing ${files[$file]}: $file"
            exit 1
          fi
          echo "‚úÖ Found ${files[$file]}"
        done
        
        echo "‚úÖ Modular structure validation complete"
      working-directory: .
        
    - name: Run NewHomeSource modular scraper
      id: scraper
      env:
        MONGO_DB_USERNAME: ${{ secrets.MONGO_DB_USERNAME }}
        MONGO_DB_PASSWORD: ${{ secrets.MONGO_DB_PASSWORD }}
        MONGO_DB_URI: mongodb+srv://${{ secrets.MONGO_DB_USERNAME }}:${{ secrets.MONGO_DB_PASSWORD }}@cluster0.lz6kt.mongodb.net/newhomesource?retryWrites=true&w=majority&appName=Cluster0
      run: |
        # Get input parameters (with defaults for scheduled runs)
        STAGE="${{ github.event.inputs.stage || 'full' }}"
        MAX_CONCURRENT="${{ github.event.inputs.max_concurrent || '8' }}"
        BROWSER_INPUT="${{ github.event.inputs.browser || 'auto' }}"
        
        echo "üöÄ Starting NewHomeSource modular scraper"
        echo "üìä Configuration:"
        echo "   Stage: $STAGE"
        echo "   Max Concurrent: $MAX_CONCURRENT"
        echo "   Browser Input: $BROWSER_INPUT"
        echo ""
        
        # Determine browser strategy
        if [ "$BROWSER_INPUT" = "auto" ]; then
          echo "üîÑ Using browser fallback strategy"
          BROWSERS=("chrome" "firefox" "safari" "chrome_android" "safari_ios")
          USE_FALLBACK=true
        else
          echo "üéØ Using specified browser: $BROWSER_INPUT"
          BROWSERS=("$BROWSER_INPUT")
          USE_FALLBACK=false
        fi
        
        SUCCESS=false
        SUCCESSFUL_BROWSER=""
        FINAL_EXIT_CODE=1
        
        echo "üìã Browser order: ${BROWSERS[*]}"
        echo "üéØ Running with consolidated run_nhs.py (modular architecture)"
        echo ""
        
        for browser in "${BROWSERS[@]}"; do
          echo "üåê Attempting extraction with browser: $browser"
          echo "========================================"
          
          # Build command with enhanced logging
          CMD="python run_nhs.py --stage $STAGE --max-concurrent $MAX_CONCURRENT --browser $browser --verbose"
          echo "üíª Command: $CMD"
          echo ""
          
          if $CMD; then
            echo "‚úÖ SUCCESS with browser: $browser"
            SUCCESS=true
            SUCCESSFUL_BROWSER="$browser"
            FINAL_EXIT_CODE=0
            break
          else
            EXIT_CODE=$?
            echo "‚ùå FAILED with browser: $browser (exit code: $EXIT_CODE)"
            echo ""
            
            # Show last few lines of the latest log for debugging
            LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
            if [ -n "$LOG_FILE" ]; then
              echo "üìã Last 15 lines from $LOG_FILE:"
              tail -n 15 "$LOG_FILE"
              echo ""
            fi
            
            # Only wait if using fallback and not the last browser
            if [ "$USE_FALLBACK" = true ] && [ "$browser" != "${BROWSERS[-1]}" ]; then
              echo "‚è≥ Waiting 30 seconds before trying next browser..."
              sleep 30
            fi
          fi
        done
        
        echo "========================================"
        if [ "$SUCCESS" = true ]; then
          echo "üéâ NEWHOMESOURCE MODULAR EXTRACTION COMPLETED SUCCESSFULLY"
          echo "‚úÖ Browser used: $SUCCESSFUL_BROWSER"
          echo "üìä Stage completed: $STAGE"
          if [ "$STAGE" = "full" ]; then
            echo "‚úÖ Stage 1 (listings) and Stage 2 (community data) both completed"
            echo "üí∞ Price tracking data captured and stored"
          elif [ "$STAGE" = "1" ]; then
            echo "‚úÖ Stage 1 (listings) completed"
          elif [ "$STAGE" = "2" ]; then
            echo "‚úÖ Stage 2 (community data) completed"
            echo "üí∞ Price tracking data captured and stored"
          fi
          echo "successful_browser=$SUCCESSFUL_BROWSER" >> $GITHUB_OUTPUT
          echo "stage_completed=$STAGE" >> $GITHUB_OUTPUT
        else
          echo "üí• MODULAR EXTRACTION FAILED"
          echo "‚ùå Stage attempted: $STAGE"
          if [ "$USE_FALLBACK" = true ]; then
            echo "‚ùå All browsers failed: ${BROWSERS[*]}"
          else
            echo "‚ùå Browser failed: $BROWSER_INPUT"
          fi
          echo "successful_browser=none" >> $GITHUB_OUTPUT
          echo "stage_completed=none" >> $GITHUB_OUTPUT
        fi
        
        echo "SCRAPER_EXIT_CODE=$FINAL_EXIT_CODE" >> $GITHUB_OUTPUT
        exit $FINAL_EXIT_CODE
      working-directory: .              
        
    - name: Check modular scraper results
      run: |
       
        echo "=== NEWHOMESOURCE MODULAR EXTRACTION SUMMARY ==="
        
        # Get stage that was attempted
        STAGE_ATTEMPTED="${{ steps.scraper.outputs.stage_completed || 'unknown' }}"
        echo "üìä Stage attempted: $STAGE_ATTEMPTED"
        echo ""
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          echo "üìã Log file: $LOG_FILE"
          echo ""
          echo "=== LAST 25 LINES OF LOG ==="
          tail -n 25 "$LOG_FILE"
          echo ""
          
          # Check for success/failure indicators based on modular architecture
          STAGE1_SUCCESS=$(grep -c "üèÅ Stage 1 Extraction Complete!" "$LOG_FILE" || echo "0")
          STAGE2_SUCCESS=$(grep -c "üèÅ Stage 2 Extraction Complete!" "$LOG_FILE" || echo "0")
          OVERALL_SUCCESS=$(grep -c "üéä FULL EXTRACTION SUMMARY" "$LOG_FILE" || echo "0")
          MODULAR_SUCCESS=$(grep -c "üéâ.*completed successfully" "$LOG_FILE" || echo "0")
          
          # Determine status based on stage attempted and modular success indicators
          if [ "$STAGE_ATTEMPTED" = "full" ]; then
            if [ "$OVERALL_SUCCESS" -gt 0 ] && [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -gt 0 ]; then
              echo "‚úÖ EXTRACTION STATUS: FULL SUCCESS (Both Stages)"
              echo "‚úÖ Stage 1 (Listings): COMPLETED"
              echo "‚úÖ Stage 2 (Community Data): COMPLETED"
              echo "scraper_status=success" >> $GITHUB_OUTPUT
            elif [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -eq 0 ]; then
              echo "‚ö†Ô∏è EXTRACTION STATUS: PARTIAL SUCCESS"
              echo "‚úÖ Stage 1 (Listings): COMPLETED"
              echo "‚ùå Stage 2 (Community Data): FAILED"
              echo "scraper_status=partial" >> $GITHUB_OUTPUT
            elif [ "$MODULAR_SUCCESS" -gt 0 ]; then
              echo "‚úÖ EXTRACTION STATUS: MODULAR SUCCESS"
              echo "‚úÖ Consolidated modular extraction completed"
              echo "scraper_status=success" >> $GITHUB_OUTPUT
            else
              echo "‚ùå EXTRACTION STATUS: FAILED"
              echo "‚ùå Full extraction failed"
              echo "scraper_status=failed" >> $GITHUB_OUTPUT
            fi
          elif [ "$STAGE_ATTEMPTED" = "1" ]; then
            if [ "$STAGE1_SUCCESS" -gt 0 ] || [ "$MODULAR_SUCCESS" -gt 0 ]; then
              echo "‚úÖ EXTRACTION STATUS: STAGE 1 SUCCESS"
              echo "‚úÖ Stage 1 (Listings): COMPLETED"
              echo "scraper_status=success" >> $GITHUB_OUTPUT
            else
              echo "‚ùå EXTRACTION STATUS: STAGE 1 FAILED"
              echo "‚ùå Stage 1 (Listings): FAILED"
              echo "scraper_status=failed" >> $GITHUB_OUTPUT
            fi
          elif [ "$STAGE_ATTEMPTED" = "2" ]; then
            if [ "$STAGE2_SUCCESS" -gt 0 ] || [ "$MODULAR_SUCCESS" -gt 0 ]; then
              echo "‚úÖ EXTRACTION STATUS: STAGE 2 SUCCESS"
              echo "‚úÖ Stage 2 (Community Data): COMPLETED"
              echo "scraper_status=success" >> $GITHUB_OUTPUT
            else
              echo "‚ùå EXTRACTION STATUS: STAGE 2 FAILED"
              echo "‚ùå Stage 2 (Community Data): FAILED"
              echo "scraper_status=failed" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è EXTRACTION STATUS: UNKNOWN"
            echo "scraper_status=unknown" >> $GITHUB_OUTPUT
          fi
          
          # Show errors if any
          echo ""
          echo "=== ERRORS FOUND ==="
          grep "‚ùå" "$LOG_FILE" | head -n 10 || echo "No specific errors found in log"
          
          # Extract statistics from modular execution
          echo ""
          echo "=== MODULAR EXECUTION STATISTICS ==="
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç|üÜï|üîÑ|‚úÖ)" "$LOG_FILE" | grep -E "(processed|new|updated|success|error|completed|stats)" | tail -n 12
          
        else
          echo "‚ùå No log file found - modular scraper may have failed to start"
          echo "scraper_status=no_log" >> $GITHUB_OUTPUT
        fi
        
    - name: Upload logs and data
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: modular-scraper-logs-${{ github.run_number }}
        path: |
          src/scraper/logging/nhs/scraper_log_*.log
        retention-days: 7
        
    - name: Report modular scraper status in job summary
      if: always()
      run: |
        echo "# üè† NewHomeSource Modular Extraction Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Time:** $(date) (Scheduled for 6 AM PST)" >> $GITHUB_STEP_SUMMARY
        echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "**Successful Browser:** ${{ steps.scraper.outputs.successful_browser }}" >> $GITHUB_STEP_SUMMARY
        echo "**Stage Completed:** ${{ steps.scraper.outputs.stage_completed }}" >> $GITHUB_STEP_SUMMARY
        echo "**Architecture:** Modular (stageone + stagetwo + shared)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Find the latest log file
        LOG_FILE=$(ls -t logging/nhs/scraper_log_*.log 2>/dev/null | head -n1)
        
        if [ -n "$LOG_FILE" ]; then
          # Check for success/failure indicators based on modular architecture
          STAGE1_SUCCESS=$(grep -c "üèÅ Stage 1 Extraction Complete!" "$LOG_FILE" || echo "0")
          STAGE2_SUCCESS=$(grep -c "üèÅ Stage 2 Extraction Complete!" "$LOG_FILE" || echo "0")
          OVERALL_SUCCESS=$(grep -c "üéä FULL EXTRACTION SUMMARY" "$LOG_FILE" || echo "0")
          MODULAR_SUCCESS=$(grep -c "üéâ.*completed successfully" "$LOG_FILE" || echo "0")
          STAGE_ATTEMPTED="${{ steps.scraper.outputs.stage_completed }}"
          
          # Determine status based on stage attempted and modular success indicators
          if [ "$STAGE_ATTEMPTED" = "full" ]; then
            if [ "$OVERALL_SUCCESS" -gt 0 ] && [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -gt 0 ]; then
              echo "## ‚úÖ Status: FULL SUCCESS (Both Stages)" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ Stage 1 (Listings): COMPLETED" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ Stage 2 (Community Data): COMPLETED" >> $GITHUB_STEP_SUMMARY
              echo "- üí∞ Price Tracking: ACTIVE" >> $GITHUB_STEP_SUMMARY
            elif [ "$MODULAR_SUCCESS" -gt 0 ]; then
              echo "## ‚úÖ Status: MODULAR SUCCESS" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ Consolidated modular extraction completed" >> $GITHUB_STEP_SUMMARY
              echo "- üí∞ Price Tracking: ACTIVE" >> $GITHUB_STEP_SUMMARY
            elif [ "$STAGE1_SUCCESS" -gt 0 ] && [ "$STAGE2_SUCCESS" -eq 0 ]; then
              echo "## ‚ö†Ô∏è Status: PARTIAL SUCCESS" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ Stage 1 (Listings): COMPLETED" >> $GITHUB_STEP_SUMMARY
              echo "- ‚ùå Stage 2 (Community Data): FAILED" >> $GITHUB_STEP_SUMMARY
            else
              echo "## ‚ùå Status: FAILED" >> $GITHUB_STEP_SUMMARY
              echo "- ‚ùå Full extraction failed" >> $GITHUB_STEP_SUMMARY
            fi
          elif [ "$STAGE_ATTEMPTED" = "1" ]; then
            if [ "$STAGE1_SUCCESS" -gt 0 ] || [ "$MODULAR_SUCCESS" -gt 0 ]; then
              echo "## ‚úÖ Status: STAGE 1 SUCCESS" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ Stage 1 (Listings): COMPLETED" >> $GITHUB_STEP_SUMMARY
            else
              echo "## ‚ùå Status: STAGE 1 FAILED" >> $GITHUB_STEP_SUMMARY
              echo "- ‚ùå Stage 1 (Listings): FAILED" >> $GITHUB_STEP_SUMMARY
            fi
          elif [ "$STAGE_ATTEMPTED" = "2" ]; then
            if [ "$STAGE2_SUCCESS" -gt 0 ] || [ "$MODULAR_SUCCESS" -gt 0 ]; then
              echo "## ‚úÖ Status: STAGE 2 SUCCESS" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ Stage 2 (Community Data): COMPLETED" >> $GITHUB_STEP_SUMMARY
              echo "- üí∞ Price Tracking: ACTIVE" >> $GITHUB_STEP_SUMMARY
            else
              echo "## ‚ùå Status: STAGE 2 FAILED" >> $GITHUB_STEP_SUMMARY
              echo "- ‚ùå Stage 2 (Community Data): FAILED" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "## ‚ö†Ô∏è Status: UNKNOWN" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ö†Ô∏è Stage attempted: $STAGE_ATTEMPTED" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Modular Execution Statistics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          grep -E "(üìä|üè†|‚ö†Ô∏è|üíæ|üîç|üÜï|üîÑ|‚úÖ)" "$LOG_FILE" | grep -E "(processed|new|updated|success|error|completed|stats)" | tail -n 10 >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Show any errors
          if grep -q "‚ùå" "$LOG_FILE"; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ö†Ô∏è Errors Encountered" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            grep "‚ùå" "$LOG_FILE" | head -n 10 >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
          
        else
          echo "## ‚ùå Status: NO LOG FILE" >> $GITHUB_STEP_SUMMARY
          echo "Modular scraper failed to generate log file." >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Fail job if modular scraper failed
      if: failure() || steps.scraper.outputs.SCRAPER_EXIT_CODE != '0'
      run: |
        echo "‚ùå NewHomeSource modular extraction failed with exit code: ${{ steps.scraper.outputs.SCRAPER_EXIT_CODE }}"
        echo "‚ùå Stage attempted: ${{ steps.scraper.outputs.stage_completed || 'unknown' }}"
        echo "‚ùå Successful browser: ${{ steps.scraper.outputs.successful_browser || 'none' }}"
        echo "‚ùå Architecture: Modular (stageone + stagetwo + shared)"
        echo "‚ùå Check modular extraction logs for details"
        exit 1
