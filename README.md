# ğŸ  NewHomeSource Scraper

> **What does this do?** This is like a smart robot that visits websites to collect information about new houses for sale, just like how you might look through different stores to find the best toys!

## ğŸ¯ What This Scraper Does

This scraper is like a **house-hunting assistant** that:

1. **Visits house websites** (like NewHomeSource.com)
2. **Collects information** about houses for sale
3. **Organizes the data** in a neat database
4. **Tracks price changes** over time
5. **Finds detailed information** about each neighborhood

## ğŸ—ï¸ How It's Organized

Think of this like organizing your toys into different boxes:

```
scraper/
â”œâ”€â”€ ğŸ“¦ run_nhs.py          â† The MAIN controller (like the boss of all robots)
â”œâ”€â”€ ğŸ“ stageone/           â† Stage 1: Find all the houses
â”œâ”€â”€ ğŸ“ stagetwo/           â† Stage 2: Get details about each house  
â”œâ”€â”€ ğŸ“ shared/             â† Tools that both stages use
â”œâ”€â”€ ğŸ“ test/               â† Check if everything works correctly
â””â”€â”€ ğŸ“„ scraper_config.json â† Settings file (like instructions)
```

## ğŸš€ How to Use It

### Simple Commands (like giving instructions to your robot):

```bash
# Get ALL house information (most common)
python run_nhs.py --stage full

# Only find house listings (Stage 1)
python run_nhs.py --stage 1

# Only get detailed house info (Stage 2) 
python run_nhs.py --stage 2

# Make it work faster (more robots working at once)
python run_nhs.py --max-concurrent 15

# See lots of details while it's working
python run_nhs.py --verbose
```

## ğŸª The Two Main Jobs

### ğŸ  Stage 1: House Finder
- **What it does:** Goes to websites and finds ALL the houses for sale
- **Like:** Walking through every street in a neighborhood to count all the houses
- **Result:** Makes a big list of house addresses

### ğŸ˜ï¸ Stage 2: Detail Collector  
- **What it does:** Visits each house from Stage 1 to get detailed information
- **Like:** Knocking on each door to ask about the house (rooms, price, etc.)
- **Result:** Detailed information about each house and neighborhood

## ğŸ’¾ Where Information Goes

All the house information gets saved in **MongoDB** (like a giant digital filing cabinet):

- **homepagedata** â†’ Basic house listings
- **communitydata** â†’ Detailed neighborhood information  
- **pricehistory** â†’ How prices change over time
- **archivedlistings** â†’ Houses that are no longer for sale

## ğŸ“‹ What You Need

Before running the scraper:

1. **MongoDB** â†’ Database to store information
2. **Python packages** â†’ Install with `pip install -r requirements.txt`
3. **Environment file** â†’ Create `.env` file with `MONGO_DB_URI=your_database_connection`

## ğŸ® Cool Features

- **Smart Retries** â†’ If something fails, it tries again automatically
- **Browser Switching** â†’ Can pretend to be different web browsers
- **Price Tracking** â†’ Remembers how house prices change over time
- **Change Detection** â†’ Only updates information that actually changed
- **Progress Reports** â†’ Shows you what it's doing while it works

## ğŸ› ï¸ For Developers

Each folder has its own README with more technical details:
- [stageone/README.md](stageone/README.md) - Stage 1 components
- [stagetwo/README.md](stagetwo/README.md) - Stage 2 components  
- [shared/README.md](shared/README.md) - Common utilities

## ğŸš¨ Important Files

- **run_nhs.py** â†’ Main program (start here!)
- **scraper_config.json** â†’ Settings for what to scrape
- **requirements.txt** â†’ List of needed Python packages

## ğŸ‰ Example Output

When it's working, you'll see messages like:
```
ğŸš€ Starting Stage 1 Listing Extraction...
âœ… Found 150 properties to process
ğŸƒâ€â™‚ï¸ Starting Stage 2 Community Extraction...  
âœ… Community data and price snapshots captured
ğŸ‰ Complete data extraction successful!
```

---
*This scraper helps people find and track house information automatically, making house hunting much easier!* ğŸ¡
